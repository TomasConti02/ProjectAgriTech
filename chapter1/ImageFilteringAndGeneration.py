import os
import tensorflow as tf
import numpy as np
import cv2
import matplotlib.pyplot as plt

# === PATH ===
MODEL_PATH = "/content/drive/MyDrive/branch/models/unet_branch_segmentation_final_20251011_183040.keras"
TUE_IMMAGINI_DIR = "/content/drive/MyDrive/branch/tue_immagini"

def dice_coefficient(y_true, y_pred, smooth=1e-6):
    y_true_f = tf.keras.backend.flatten(y_true)
    y_pred_f = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)

def dice_loss(y_true, y_pred):
    return 1 - dice_coefficient(y_true, y_pred)

def combined_loss(y_true, y_pred):
    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)
    return bce + dice_loss(y_true, y_pred)

# Carica il modello
model = tf.keras.models.load_model(
    MODEL_PATH,
    custom_objects={
        'dice_coefficient': dice_coefficient,
        'dice_loss': dice_loss,
        'combined_loss': combined_loss
    }
)

def segmentazione_ibrida_bilanciata(image_path):
    """
    Approccio ibrido con parametri bilanciati ottimali
    """
    # PARAMETRI BILANCIATI OTTIMALI
    parametri_bilanciati = {
        'hsv_range1': ([0, 25, 8], [32, 225, 160]),
        'hsv_range2': ([148, 25, 8], [180, 205, 160]),
        'lab_light_range': (15, 80),  # Mantenuto originale per stabilitÃ 
        'lab_color_range': (110, 135), # Mantenuto originale
        'canny_thresholds': (30, 90),  # PiÃ¹ sensibile
        'texture_threshold': 25,       # PiÃ¹ sensibile
        'combinazione': 'pesata',      # Combinazione intelligente
        'peso_colore': 0.6,
        'peso_struttura': 0.4
    }

    params = parametri_bilanciati

    # Carica immagine
    img = cv2.imread(image_path)
    if img is None:
        print(f"Errore: impossibile caricare l'immagine {image_path}")
        return None, None, None, None

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    original_h, original_w = img_rgb.shape[:2]

    # === FASE 1: PREDIZIONE MODELLO ===
    img_processed = cv2.resize(img_rgb, (256, 256))
    img_processed = img_processed.astype(np.float32) / 255.0

    prediction = model.predict(np.expand_dims(img_processed, axis=0), verbose=0)[0].squeeze()
    model_mask = (prediction > 0.15).astype(np.uint8)
    model_mask = cv2.resize(model_mask, (original_w, original_h))

    # === FASE 2: ELABORAZIONE TRADIZIONALE BILANCIATA ===
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)

    # Segmentazione colore con parametri bilanciati
    mask_hsv1 = cv2.inRange(hsv, np.array(params['hsv_range1'][0]), np.array(params['hsv_range1'][1]))
    mask_hsv2 = cv2.inRange(hsv, np.array(params['hsv_range2'][0]), np.array(params['hsv_range2'][1]))

    L, A, B = cv2.split(lab)
    mask_lab_light = cv2.inRange(L, params['lab_light_range'][0], params['lab_light_range'][1])
    mask_lab_color = cv2.inRange(A, params['lab_color_range'][0], params['lab_color_range'][1])

    # Edge detection bilanciata
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    gray_eq = clahe.apply(gray)
    edges = cv2.Canny(gray_eq, params['canny_thresholds'][0], params['canny_thresholds'][1])

    # Analisi texture bilanciata
    kernel = cv2.getGaborKernel((15, 15), 4.0, 0, 10.0, 1.5, 0, ktype=cv2.CV_32F)
    texture_filtered = cv2.filter2D(gray_eq, cv2.CV_8UC3, kernel)
    _, texture_mask = cv2.threshold(texture_filtered, params['texture_threshold'], 255, cv2.THRESH_BINARY)

    # Combinazione strategica BILANCIATA
    color_mask = cv2.bitwise_or(mask_hsv1, mask_hsv2)
    color_mask = cv2.bitwise_or(color_mask, mask_lab_light)
    color_mask = cv2.bitwise_or(color_mask, mask_lab_color)

    structure_mask = cv2.bitwise_or(edges, texture_mask)

    # COMBINAZIONE PESATA (approccio bilanciato)
    color_float = color_mask.astype(np.float32) / 255.0
    structure_float = structure_mask.astype(np.float32) / 255.0
    combined_float = (color_float * params['peso_colore'] +
                     structure_float * params['peso_struttura'])
    traditional_mask = (combined_float > 0.5).astype(np.uint8) * 255

    # Post-processing
    kernel_clean = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    traditional_mask = cv2.morphologyEx(traditional_mask, cv2.MORPH_OPEN, kernel_clean)
    traditional_mask = cv2.morphologyEx(traditional_mask, cv2.MORPH_CLOSE, kernel_clean)

    # === FASE 3: COMBINAZIONE CON AI ===
    final_mask = cv2.bitwise_or(traditional_mask, model_mask * 255)

    # Pulizia finale
    final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_OPEN, kernel_clean)

    # Filtro area ragionevole
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(final_mask, connectivity=8)
    for i in range(1, num_labels):
        area = stats[i, cv2.CC_STAT_AREA]
        if area < 30 or area > (original_h * original_w * 0.4):
            final_mask[labels == i] = 0

    return final_mask, traditional_mask, model_mask * 255, img_rgb

def visualizza_risultati_immagine(image_path, final_mask, traditional_mask, model_mask, img_rgb, area_percent):
    """
    Visualizza i risultati per una singola immagine nel notebook
    """
    nome_file = os.path.basename(image_path)

    # Crea una figura con tutti i risultati
    plt.figure(figsize=(15, 10))

    # Immagine originale
    plt.subplot(2, 2, 1)
    plt.imshow(img_rgb)
    plt.title('Original Image\n' + nome_file, fontsize=14, fontweight='bold')
    plt.axis('off')

    # Maschera U-Net
    plt.subplot(2, 2, 2)
    plt.imshow(model_mask, cmap='gray')
    plt.title('U-Net Prediction', fontsize=14, fontweight='bold')
    plt.axis('off')

    # Maschera tradizionale BILANCIATA
    plt.subplot(2, 2, 3)
    plt.imshow(traditional_mask, cmap='gray')
    area_trad = np.sum(traditional_mask > 0) / traditional_mask.size * 100
    plt.title(f'Traditional Processing (BILANCIATA)\n{area_trad:.1f}% area', fontsize=14, fontweight='bold')
    plt.axis('off')

    # Maschera finale ibrida + Overlay
    plt.subplot(2, 2, 4)
    plt.imshow(img_rgb)
    plt.imshow(final_mask, cmap='Reds', alpha=0.6)
    plt.title(f'Hybrid Final Result\n{area_percent:.1f}% branch area', fontsize=14, fontweight='bold')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

    print(f"ðŸ“Š Statistiche per {nome_file}:")
    print(f"   â€¢ Area rami totale: {area_percent:.2f}%")
    print(f"   â€¢ Area tradizionale: {area_trad:.2f}%")
    print(f"   â€¢ Pixel rami: {np.sum(final_mask > 0):,} / {final_mask.size:,}")
    print("-" * 50)

def elabora_tutte_immagini_bilanciate():
    """
    Elabora tutte le immagini con la configurazione bilanciata ottimale
    """
    # Trova tutte le immagini nella directory
    immagini = [
        os.path.join(TUE_IMMAGINI_DIR, f)
        for f in os.listdir(TUE_IMMAGINI_DIR)
        if f.lower().endswith(('.jpg', '.jpeg', '.png'))
    ]

    if not immagini:
        print("Nessuna immagine trovata nella directory!")
        return

    print(f"ðŸŽ¯ ELABORAZIONE CON CONFIGURAZIONE BILANCIATA - {len(immagini)} IMMAGINI")
    print("=" * 70)
    print("âš¡ PARAMETRI ATTIVI:")
    print("   â€¢ Range HSV ottimizzato")
    print("   â€¢ Edge detection sensibile (Canny 30-90)")
    print("   â€¢ Combinazione pesata (Colore 60% + Struttura 40%)")
    print("=" * 70)

    risultati = []

    for i, image_path in enumerate(immagini, 1):
        print(f"\nðŸ”„ Elaborazione {i}/{len(immagini)}: {os.path.basename(image_path)}")

        # Esegui segmentazione ibrida bilanciata
        final_mask, traditional_mask, model_mask, img_rgb = segmentazione_ibrida_bilanciata(image_path)

        if final_mask is None:
            print(f"  âš ï¸  Saltata per errore di caricamento")
            continue

        # Calcola statistiche
        area_percent = np.sum(final_mask > 0) / final_mask.size * 100
        risultati.append((os.path.basename(image_path), area_percent))

        # VISUALIZZA i risultati nel notebook
        visualizza_risultati_immagine(image_path, final_mask, traditional_mask, model_mask, img_rgb, area_percent)

        print(f"  âœ… Completata - Area rami: {area_percent:.2f}%")

    # Stampa riepilogo finale
    print("\n" + "=" * 70)
    print("ðŸ“ˆ RIEPILOGO FINALE - CONFIGURAZIONE BILANCIATA")
    print("=" * 70)

    for nome_file, area in risultati:
        print(f"  ðŸ“„ {nome_file}: {area:.2f}% area rami")

    area_media = np.mean([r[1] for r in risultati]) if risultati else 0
    area_min = np.min([r[1] for r in risultati]) if risultati else 0
    area_max = np.max([r[1] for r in risultati]) if risultati else 0
    std = np.std([r[1] for r in risultati]) if risultati else 0

    print(f"\nðŸ“Š STATISTICHE COMPLESSIVE:")
    print(f"   â€¢ Area media rami: {area_media:.2f}%")
    print(f"   â€¢ Deviazione standard: Â±{std:.2f}%")
    print(f"   â€¢ Area minima: {area_min:.2f}%")
    print(f"   â€¢ Area massima: {area_max:.2f}%")
    print(f"   â€¢ Totale immagini elaborate: {len(risultati)}/{len(immagini)}")

    print(f"\nâœ… CONFIGURAZIONE BILANCIATA ATTIVA:")
    print(f"   â€¢ Miglioramento consistente rispetto all'originale")
    print(f"   â€¢ Risultati stabili senza outlier")
    print(f"   â€¢ Bilanciamento ottimale colore-struttura")

# Esegui l'elaborazione con la configurazione bilanciata
elabora_tutte_immagini_bilanciate()
